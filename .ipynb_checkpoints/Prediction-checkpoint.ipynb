{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Let's try random forest. I'd like to start with random forest because I will like to see how different features stack up using feature importances.\n",
    "\n",
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaned_bank_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's take all the features in for prediction\n",
    "predictors = list(df.drop('y',axis=1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Random Forest Parameters\n",
    "** 1. n_estimators - ** The number of trees in the forest\n",
    "\n",
    "** 2. gini - ** The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and\n",
    "                “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "                \n",
    "** 3. max_features - ** The number of features to consider when looking for the best split\n",
    "\n",
    "** 4. max_features - ** The number of features to consider when looking for the best split\n",
    "\n",
    "** 5. min_samples_leaf - ** The number of trees in the forest\n",
    "\n",
    "** 6. n_estimators - ** The number of trees in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-17fd490c1e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named model_selection"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "rf = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=10, \n",
    "                            min_samples_leaf=10)\n",
    "kf = KFold(df.shape[0], n_folds=5, random_state=1)\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.3, random_state=50)\n",
    "\n",
    "predictions = cross_validation.cross_val_predict(rf, df[predictors],df[\"y\"],cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "scores = cross_val_score(rf, df[predictors], df[\"y\"],\n",
    "                                          scoring='f1', cv=kf)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to swing different parameters to see how accuracy changes\n",
    "\n",
    "**1. n_estimators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ShuffleSplit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b870eca0e44f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscorelist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ShuffleSplit' is not defined"
     ]
    }
   ],
   "source": [
    "predictors = list(df.drop('y',axis=1).columns)\n",
    "\n",
    "kf = KFold(df.shape[0], n_folds=5, random_state=1)\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.3, random_state=50)\n",
    "scorelist = []\n",
    "r = list(range(1,25,2))\n",
    "\n",
    "for i in r:\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=1, n_estimators=i, min_samples_split=10, \n",
    "                            min_samples_leaf=10)\n",
    "    \n",
    "    predictions = cross_validation.cross_val_predict(rf, df[predictors],df[\"y\"],cv=kf)\n",
    "    predictions = pd.Series(predictions)\n",
    "    scores = cross_val_score(rf, df[predictors], df[\"y\"], scoring='f1', cv=kf)\n",
    "    scorelist.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"Sweeping - n_estimators\")\n",
    "plt.plot(r,scorelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. min_samples_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = list(df.drop('y',axis=1).columns)\n",
    "\n",
    "kf = KFold(df.shape[0], n_folds=5, random_state=1)\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.3, random_state=50)\n",
    "scorelist = []\n",
    "r = list(range(60,65,1))\n",
    "\n",
    "for i in r:\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=i, \n",
    "                            min_samples_leaf=10)\n",
    "    \n",
    "    predictions = cross_validation.cross_val_predict(rf, df[predictors],df[\"y\"],cv=kf)\n",
    "    predictions = pd.Series(predictions)\n",
    "    scores = cross_val_score(rf, df[predictors], df[\"y\"], scoring='f1', cv=kf)\n",
    "    scorelist.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"Sweeping - min_samples_split\")\n",
    "plt.plot(r,scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "#plt.figure(figsize=(7,4))\n",
    "#plt.title(\"Sweeping - min_samples_split\")\n",
    "#plt.plot(r,scorelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. min_samples_leaf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = list(df.drop('y',axis=1).columns)\n",
    "\n",
    "kf = KFold(df.shape[0], n_folds=5, random_state=1)\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.3, random_state=50)\n",
    "scorelist = []\n",
    "r = list(range(2,500,10))\n",
    "\n",
    "for i in r:\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=62, \n",
    "                            min_samples_leaf=i)\n",
    "    \n",
    "    predictions = cross_validation.cross_val_predict(rf, df[predictors],df[\"y\"],cv=kf)\n",
    "    predictions = pd.Series(predictions)\n",
    "    scores = cross_val_score(rf, df[predictors], df[\"y\"], scoring='f1', cv=kf)\n",
    "    scorelist.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"Sweeping - min_samples_leaf\")\n",
    "plt.plot(r,scorelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1, n_estimators=100,min_samples_leaf=2)\n",
    "rf.fit(df[predictors],df[\"y\"])\n",
    "kf = KFold(df.shape[0], n_folds=5, random_state=1)\n",
    "predictions = cross_validation.cross_val_predict(rf, df[predictors],df[\"y\"],cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "scores = cross_val_score(rf, df[predictors], df[\"y\"],scoring='f1', cv=kf)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances=rf.feature_importances_\n",
    "std = np.std([rf.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_important_features=[]\n",
    "for i in indices:\n",
    "    sorted_important_features.append(predictors[i])\n",
    "#predictors=titanic.columns\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Feature Importances By Random Forest Model\")\n",
    "plt.bar(range(np.size(predictors)), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n",
    "\n",
    "plt.xlim([-1, np.size(predictors)])\n",
    "print(sorted_important_features[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try by only selecting the top features until housing. Same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = sorted_important_features[0:12]\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1, n_estimators=100)\n",
    "rf.fit(df[predictors],df[\"y\"])\n",
    "kf = KFold(df.shape[0], n_folds=5, random_state=1)\n",
    "predictions = cross_validation.cross_val_predict(rf, df[predictors],df[\"y\"],cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "scores = cross_val_score(rf, df[predictors], df[\"y\"],scoring='f1', cv=kf)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
