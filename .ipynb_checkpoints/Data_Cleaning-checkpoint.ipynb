{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Just to suppress some warnings about copying data on a slice of a dataframe\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41188\n",
      "['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./bank-additional/bank-additional-full.csv',delimiter=';')\n",
    "df = df.drop('duration',axis=1)\n",
    "print(\"Size of dataset - \",len(df))\n",
    "print(\" Columns - \", list(df.columns))\n",
    "#encoding y\n",
    "df['y'] = df['y'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.job.v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiying the columns with data-types -\n",
    "#### 1.Numerical Data\n",
    "#### 2. Categorical Data\n",
    "##### a) Two Categories (default, housing, loan)\n",
    "    Can be encoded by mapping 0 and 1 directly\n",
    "##### b) Multiple Categories - no hierarcy (job, marital, contact, month, day_of_week, poutcome)\n",
    "    Can be encoded by create a separate column for each category\n",
    "##### c) Multiple Categories - hierarcy (education)\n",
    "    Can be encoded by assigning levels in a single category (0,1,2,etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert pdays into Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"pdays\"] == 999, \"pdayscat\"] = 0 #cutomer was not contacted for previous campaign\n",
    "df.loc[df[\"pdays\"] != 999, \"pdayscat\"] = 1 #cutomer was contacted for previous campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert age into Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2853117295\n",
      "45.6391875747\n",
      "28.0991735537\n"
     ]
    }
   ],
   "source": [
    "l1 = 23\n",
    "l2 = 62\n",
    "df.loc[df[\"age\"] <= l1, \"agecat\"] = 'young'\n",
    "df.loc[((df[\"age\"] > l1) & (df[\"age\"] < l2)), \"agecat\"] = 'adult'\n",
    "df.loc[df[\"age\"] >= l2, \"agecat\"] = 'senior'\n",
    "\n",
    "l = df.agecat.value_counts()\n",
    "a = l.index\n",
    "\n",
    "for i in a:\n",
    "    n = df.y[df.agecat == i].sum() * 100 / l[i] #% subsription for each of the categories\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Campaign into Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n",
      "11.3931217843\n",
      "2.1164021164\n"
     ]
    }
   ],
   "source": [
    "l1 = 12\n",
    "print (len(df.loc[df.campaign > l1]))\n",
    "\n",
    "df.loc[df[\"campaign\"] <= l1, \"campcat\"] = 'low'\n",
    "df.loc[df[\"campaign\"] > l1, \"campcat\"] = 'high'\n",
    "\n",
    "l = df.campcat.value_counts()\n",
    "a = l.index\n",
    "\n",
    "for i in a:\n",
    "    n = df.y[df.campcat == i].sum() * 100 / l[i] #% subsription for each of the categories\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', \n",
    "           'euribor3m', 'nr.employed']\n",
    "binary = ['default', 'housing', 'loan','contact','campcat']\n",
    "categorical = ['poutcome', 'job', 'marital', 'month','day_of_week','agecat']\n",
    "hierarchy = ['education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unknowns - dealing with null values\n",
    "\n",
    "To start with let's calculate how much is 1% of the data. If a column contains null values less than that, we'll simply delete those rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting smaller unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><code>for i in binary+categorical+hierarchy:\n",
    "    print(df[i].value_counts())</code></pre>\n",
    "    \n",
    "It was observed from this code that there are unknown values in the categorical columns, which is essentially null values. Let us only entertain the unknowns if the total number unknowns is more than 1% of that data (round that up to 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column default - still contains 8597 unknowns\n",
      "Column housing - still contains 990 unknowns\n",
      "Column loan - still contains 990 unknowns\n",
      "contact  -  0\n",
      "campcat  -  0\n",
      "poutcome  -  0\n",
      "job  -  330\n",
      "marital  -  71\n",
      "month  -  0\n",
      "day_of_week  -  0\n",
      "agecat  -  0\n",
      "Column education - still contains 1596 unknowns\n"
     ]
    }
   ],
   "source": [
    "null_cols = []\n",
    "for column in binary+categorical+hierarchy:\n",
    "    missing_count = len(df.loc[df[column] == 'unknown']['y'])\n",
    "    print (\"Null Values - \\n\")\n",
    "    #Delete few unknowns\n",
    "    if missing_count < 500:\n",
    "        print (column, \" - \", missing_count)\n",
    "        df = df[df[column] != 'unknown']\n",
    "    elif missing_count > 500:\n",
    "        #Find which columns have still retained unkowns\n",
    "        number = missing_count\n",
    "        print(\"{} - {}\".format(column,number))\n",
    "        #Turn them into np.nan\n",
    "#         df.loc[df[column] == 'unknown',column] = np.nan\n",
    "        null_cols.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables\n",
    "#### 1. Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This is specific for education. We need a manually created hierarcy as an input here.\"\"\"\n",
    "values = [\"illiterate\", \"basic.4y\", \"basic.6y\", \"basic.9y\", \"high.school\",  \"professional.course\", \"university.degree\"]\n",
    "levels = range(1,len(values)+1)\n",
    "dictionary = dict(zip(values,levels))\n",
    "df['education']=df['education'].map(dictionary)\n",
    "df['education'] = df['education'].replace('unknown', np.nan, regex=True)\n",
    "#df['education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Categorical **\n",
    "* Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def categorical_encoding(df,categorical=categorical):\n",
    "    for column in categorical:\n",
    "        \n",
    "        dummies = pd.get_dummies(df[column])\n",
    "        dummies = dummies.rename(columns = lambda x: column + '_' + str(x))\n",
    "        \n",
    "        df = pd.concat([df,dummies],axis=1)\n",
    "        df = df.drop(column,axis=1)\n",
    "    return df\n",
    "\n",
    "df = categorical_encoding(df)\n",
    "\n",
    "\n",
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for column in categorical:\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3. Binary **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for column in binary:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    \n",
    "    #Convert 'unknown' into np.nan\n",
    "    l = list(le.classes_)\n",
    "    try:\n",
    "        i = l.index('unknown')\n",
    "        df.loc[df[column] == i, column] = np.nan\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's indentify the unknown category and replace the values with np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate for null values in numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values - \n",
      " age - 0\n",
      " campaign - 0\n",
      " pdays - 0\n",
      " previous - 0\n",
      " emp.var.rate - 0\n",
      " cons.price.idx - 0\n",
      " cons.conf.idx - 0\n",
      " euribor3m - 0\n",
      " nr.employed - 0\n"
     ]
    }
   ],
   "source": [
    "print (\"Null Values in numerical columns - \")\n",
    "for column in numeric:\n",
    "    null = sum(df[column].isnull())\n",
    "    print (\" {} - {}\".format(column, str(null)))\n",
    "    if null > 0:\n",
    "        null_cols.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can move forward and predict the missing data using random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use random forest to fill null values in default, housing, loan and education\n",
    "\n",
    "Before we start this process. We have to encode y as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding y\n",
    "# df['y'] = df['y'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_unknown(trainX, trainY, testX):\n",
    "    \"\"\" Predicting unknown data using random forest\"\"\"\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    forest = forest.fit(trainX, trainY)\n",
    "    test_predictY = forest.predict(testX).astype(int)\n",
    "    return pd.DataFrame(test_predictY,index=testX.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.education.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default', 'housing', 'loan', 'education']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nachiket\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nachiket\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nachiket\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan education "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nachiket\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "print (null_cols)\n",
    "for column in null_cols:\n",
    "    \n",
    "    test_data = df[df[column].isnull()]\n",
    "    testX = test_data.drop(null_cols, axis=1)\n",
    "    train_data = df[df[column].notnull()]        \n",
    "    trainY = train_data[column]\n",
    "    trainX = train_data.drop(null_cols, axis=1)\n",
    "    #print(trainX.isnull().sum())\n",
    "    #print(trainY.value_counts())\n",
    "    test_data[column] = predict_unknown(trainX, trainY, testX)\n",
    "    df = pd.concat([train_data, test_data])\n",
    "    print(column, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "I have moved this part in the inference notebook as I think the test set should not be included while defining the normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def normalizer(data):\n",
    "    \n",
    "#     normalized = (data-min(data))/(max(data)-min(data))\n",
    "#     return normalized\n",
    "\n",
    "\n",
    "# for column in numeric+binary+hierarchy:\n",
    "#     df[column] = normalizer(df[column])\n",
    "\n",
    "# df.education = normalizer(df.education)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here's is how features looks like -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>...</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>agecat_adult</th>\n",
       "      <th>agecat_senior</th>\n",
       "      <th>agecat_young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education  default  housing  loan  contact  campaign  pdays  previous  \\\n",
       "0   56        2.0      0.0      0.0   0.0        1         1    999         0   \n",
       "2   37        5.0      0.0      2.0   0.0        1         1    999         0   \n",
       "3   40        3.0      0.0      0.0   0.0        1         1    999         0   \n",
       "4   56        5.0      0.0      0.0   2.0        1         1    999         0   \n",
       "6   59        6.0      0.0      0.0   0.0        1         1    999         0   \n",
       "\n",
       "   emp.var.rate      ...       month_oct  month_sep  day_of_week_fri  \\\n",
       "0           1.1      ...               0          0                0   \n",
       "2           1.1      ...               0          0                0   \n",
       "3           1.1      ...               0          0                0   \n",
       "4           1.1      ...               0          0                0   \n",
       "6           1.1      ...               0          0                0   \n",
       "\n",
       "   day_of_week_mon  day_of_week_thu  day_of_week_tue  day_of_week_wed  \\\n",
       "0                1                0                0                0   \n",
       "2                1                0                0                0   \n",
       "3                1                0                0                0   \n",
       "4                1                0                0                0   \n",
       "6                1                0                0                0   \n",
       "\n",
       "   agecat_adult  agecat_senior  agecat_young  \n",
       "0             1              0             0  \n",
       "2             1              0             0  \n",
       "3             1              0             0  \n",
       "4             1              0             0  \n",
       "6             1              0             0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.drop('pdays',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"clean_data_52_features.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
