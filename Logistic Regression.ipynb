{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_bank_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dropping one column each from categorical variables to avoid redunduncy\n",
    "# df = df.drop([\n",
    "#  'poutcome_success',\n",
    "#  'job_unemployed',\n",
    "#  'marital_divorced',\n",
    "#  'month_apr',\n",
    "#  'day_of_week_fri'],axis=1)\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "features = df.drop('y',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets for final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Xtest, y, ytest = train_test_split(features.values, df['y'].values,random_state=5,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cv_score(clf, x, y, score_func=accuracy_score): #Apply k-fold cross velidation\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908455571172\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, X, y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum score of 0.9085168644608128 is achieved at C = 100\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "max_score = 0\n",
    "# your turn\n",
    "for C in Cs:\n",
    "    clf = LogisticRegression(C=C)\n",
    "    score = cv_score(clf, X, y)\n",
    "#     print (score)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        Cfinal = C\n",
    "print (\"Maximum score of {} is achieved at C = {}\".format(max_score,Cfinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908801176759\n"
     ]
    }
   ],
   "source": [
    "# your turn\n",
    "clf = LogisticRegression(C=Cfinal)\n",
    "clf.fit(X, y)\n",
    "print(accuracy_score(clf.predict(Xtest), ytest))\n",
    "#clf.score(Xtestlr,ytestlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 1 : No feature scaling, including all the features - 0.909168913949\n",
    "\n",
    "Attempt 2 : Removed the features containing redundant information (derived from categorical variables) - 0.908188281442\n",
    "\n",
    "Attempt 3 : Attempt 1 + Feature Scaling - 0.910026967394\n",
    "\n",
    "Attempt 4 : Attempt 2 + Feature Scaling - 0.910026967394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7096,  143],\n",
       "       [ 601,  318]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(ytest, clf.predict(Xtest))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
